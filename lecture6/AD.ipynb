{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Automatic Differentiation\n",
    "AD is an extremely powerful tool. In julia, you can differentiate almost any valid julia program to obtain derivatives, gradients, jacobians and hessians etc. automatically, with high performance. This is what makes up the bulk of most deep-learning libraries, but contrary to most libraries, you do not need to write your code using a subset of julia or a DL-specific language, you can just write regular julia code.\n",
    "\n",
    "There are a number of different kinds of AD. In the following, we will refer to a function \n",
    "$$ f : \\mathbb{R}^n -> \\mathbb{R}^m$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Forward-mode AD\n",
    "Using dual numbers, forward-mode AD perfrorms a single forward pass of your program, calculating both the function value and gradients in one go. FAD is algorithmically favorable when $f$ is \"few to many\", or $n < m$. It also typically has the least overhead, so is competetive when both $n$ and $m$ are small."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Reverse-mode AD\n",
    "This is what is used in DL libraries. RAD works by constructing a computation graph, either before execution (as old tensorflow) or during the execution (most common today).\n",
    "RAD is algorithmically favorable when $f$ is \"many to few\", or $n > m$. This is the case in most DL, where the cost function is a scalar-valued function of very many parameters, the NN weights. For functions with many outputs, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element Array{Float64,1}:\n",
       " 1.56704478753878  \n",
       " 1.8334625791389418\n",
       " 1.4096073759914765\n",
       " 2.032177627585189 \n",
       " 2.1173987352023795"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using ForwardDiff, BenchmarkTools\n",
    "\n",
    "f(x) = sum(sin, x) + prod(tan, x) * sum(sqrt, x);\n",
    "\n",
    "x = rand(5) # small size \n",
    "g = x -> ForwardDiff.gradient(f, x); # g = ∇f\n",
    "g(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  558.234 ns (3 allocations: 688 bytes)\n"
     ]
    }
   ],
   "source": [
    "@btime g($x);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5×5 Array{Float64,2}:\n",
       " 0.804648  2.07193  1.7873   2.41604   2.57671 \n",
       " 2.07193   0.73617  2.11972  2.86537   3.05593 \n",
       " 1.7873    2.11972  1.48638  2.47167   2.63599 \n",
       " 2.41604   2.86537  2.47167  0.815578  3.56341 \n",
       " 2.57671   3.05593  2.63599  3.56341   0.860096"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ForwardDiff.hessian(f, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Zygote\n",
    "\n",
    "gz = x -> Zygote.gradient(f, x)[1]; # g = ∇f\n",
    "gz(x) ≈ g(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  23.898 μs (321 allocations: 11.19 KiB)\n"
     ]
    }
   ],
   "source": [
    "@btime gz($x);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Flux.Tracker\n",
    "using Flux.Tracker: data\n",
    "\n",
    "gf = x -> data(Tracker.gradient(f, x)[1]) # g = ∇f\n",
    "gf(x) ≈ g(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  9.068 μs (143 allocations: 5.18 KiB)\n"
     ]
    }
   ],
   "source": [
    "@btime gf($x);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "If we change the size of the input vector, the relative timings change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  103.389 ms (5 allocations: 548.17 KiB)\n"
     ]
    }
   ],
   "source": [
    "x = rand(5000)\n",
    "@btime g($x);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#@btime gz($x);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  362.723 μs (157 allocations: 551.40 KiB)\n"
     ]
    }
   ],
   "source": [
    "@btime gf($x);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Most AD (except for Zygote and perhaps Yota) in julia works by either overloading `Base` functions on custom types. This means that you can not use AD if you restrict the input types to your functions too much! In the following example, the input is restricted to `Vector{Float64}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0202877839345177"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = abs.(randn(3))\n",
    "f2(x::Vector{Float64}) = sum(sin, x) + prod(tan, x) * sum(sqrt, x);\n",
    "f2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "ForwardDiff.gradient(f2, x);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This did not work, since ForwardDiff  calls the function with an argument of type `Vector{<: Dual}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "ename": "MethodError",
     "evalue": "MethodError: no method matching f2(::TrackedArray{…,Array{Float64,1}})\nClosest candidates are:\n  f2(!Matched::Array{Float64,1}) at In[72]:2\n  f2(!Matched::Array{T,1} where T) at In[47]:1",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching f2(::TrackedArray{…,Array{Float64,1}})\nClosest candidates are:\n  f2(!Matched::Array{Float64,1}) at In[72]:2\n  f2(!Matched::Array{T,1} where T) at In[47]:1",
      "",
      "Stacktrace:",
      " [1] gradient_(::Function, ::Array{Float64,1}) at /local/home/fredrikb/.julia/packages/Tracker/6wcYJ/src/back.jl:90",
      " [2] #gradient#24 at /local/home/fredrikb/.julia/packages/Tracker/6wcYJ/src/back.jl:164 [inlined]",
      " [3] gradient(::Function, ::Array{Float64,1}) at /local/home/fredrikb/.julia/packages/Tracker/6wcYJ/src/back.jl:164",
      " [4] top-level scope at In[74]:1"
     ]
    }
   ],
   "source": [
    "Tracker.gradient(f2, x);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This didn't work either, since `Tracker` calls the function with an argument of type `TrackedArray`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Array{Float64,1}:\n",
       " 0.528434956628905 \n",
       " 1.2242482859668935\n",
       " 1.1822048076863592"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f3(x::Vector) = sum(sin, x) + prod(tan, x) * sum(sqrt, x);\n",
    "ForwardDiff.gradient(f2, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "ename": "MethodError",
     "evalue": "MethodError: no method matching f3(::TrackedArray{…,Array{Float64,1}})\nClosest candidates are:\n  f3(!Matched::Array{T,1} where T) at In[75]:1",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching f3(::TrackedArray{…,Array{Float64,1}})\nClosest candidates are:\n  f3(!Matched::Array{T,1} where T) at In[75]:1",
      "",
      "Stacktrace:",
      " [1] gradient_(::Function, ::Array{Float64,1}) at /local/home/fredrikb/.julia/packages/Tracker/6wcYJ/src/back.jl:90",
      " [2] #gradient#24 at /local/home/fredrikb/.julia/packages/Tracker/6wcYJ/src/back.jl:164 [inlined]",
      " [3] gradient(::Function, ::Array{Float64,1}) at /local/home/fredrikb/.julia/packages/Tracker/6wcYJ/src/back.jl:164",
      " [4] top-level scope at In[76]:1"
     ]
    }
   ],
   "source": [
    "Tracker.gradient(f3, x);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Julia 1.1.0",
   "language": "julia",
   "name": "julia-1.1"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
